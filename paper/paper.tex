%\documentclass[10pt,twocolumn]{article}
\documentclass[10pt, conference]{IEEEtran}
%\IEEEoverridecommandlockouts
%\documentclass{article}
%\documentclass[12pt]{IEEEtran}
%\documentclass{elsart5p}

% Make sure we know its a draft for now
\usepackage{draftwatermark}
\usepackage{verbatim}
%\documentclass[12pt]{article}
\usepackage{epsfig}
\usepackage[hypertexnames=false,bookmarksopenlevel=1,bookmarksopen,bookmarksnumbered,colorlinks,plainpages=false,linktocpage]{hyperref}
%\usepackage{natbib}
%\pagestyle{empty}
%\psdraft
%\baselineskip=20pt %Sets line spacing to 1 unit
%\bibliographystyle{elsart-num-names}
\bibliographystyle{IEEEtran}
\usepackage{cite}
\newenvironment{definition}[1][Definition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1:}]}{\end{trivlist}}

%\begin{frontmatter}
\begin{document}
\title{The Forensic Interchange Format - a file format for digital evidence}
\author{M. I. Cohen\footnote{scudette@gmail.com} and Bradley Schatz}
%\author{M. I. Cohen}
%\address{M. I. Cohen is a Data specialist with the Australian Federal Police, Brisbane, Australia}
%\baselineskip=20pt %Sets line spacing to 1 unit
%\end{frontmatter}
%\thanks{M. I. Cohen is a Data specialist with the Australian Federal Police, Brisbane, Australia}%
\maketitle

\begin{abstract}
Forensics analysis requires the acquisition and management of many
different types of evidence material. Often the same evidence is
reviewed by several different tools. We propose an open, extensible
file format for storing of evidence and interchanging analysis results
among different tools. The Forensic Interchange Format (FIF) was
designed to be simple to implement, relying on the well supported Zip
specifications for bit level file access.
\end{abstract}

\section{Introduction}

\section{FIF Specifications}
The FIF specifications distinct between bit level specifications and
a high level schema. The bit level specifications refer to how the
files are to be actually represented on disk. The schema specifies a
stream based abstraction which is implemented using the bit level
specification. 

\subsection{FIF bit level specification}
The FIF specifications only require the underlying storage mechanism
be capable of storing multiple named segments of data. The current
specification uses the Zip file format as the underlying storage
mechanism, however in future versions of the specifications other
storage layers may be also be defined.

The Zip file specifications are publicly available and widely
implemented. The Zip64 extensions are provided to enable Zip archives
to grow beyond a two gigabyte limit by using 64 bit
references. Although Zip64 also defines encryption and authentication
extensions, we do not use these in this specification due to the
restrictions imposed on their use. Rather, we specify stream based
encryption scheme for use in FIF files (See section
\ref{crypted_stream}).

The basic structure of a Zip archive is shown in Figure
\ref{zip_structure}. For bit level details see the Zip file
Application notes \cite{zipspecs}.

\begin{figure}[tb]
  \begin{center}
  \mbox{\epsfxsize=0.8\columnwidth \epsffile{zip_structure.eps}}
  \caption{The basic structure of a Zip archive}
  \label{zip_structure}
  \end{center}
\end{figure}

As can be seen, the archive consists of a {\em Central Directory (CD)}
located at the end of the archive. The CD is a list of pointers to
individual {\em File header} structures located within the body of the
archive. Headers are then followed by the file data, after it has been
compressed by the appropriate compression method (as specified in the
header). Each archived file is optionally followed by a {\em Data
Descriptor} describing the length and CRC of the archived file. Using
the data descriptor field allows implementations to write archives
without needing to seek in the output file. This allows Zip files to
be written to pipes for example, sending an image over the network
using netcat or ssh.

\subsection{FIF Definitions}
The FIF specification defines a number of basic terms:
\begin{itemize}
\item {\em A FIF Volume} is a single ZIP archive containing {\em
segments}.

\item {\em A segment} is a single unit of data written to the Zip
archive as an archive file. The only properties of segments of
interest to the FIF specification are the segment name and the
timestamp.

\item {\em The segment name} is the name under which a segment is
stored within the archive. This consists of a directory part named
{\em a stream} and an {\em chunk name}. For example the segment named
``default/000001'' refers to the stream called ``default'' and has a
chunk name of ``000001''. Although the ZIP specification does not
specify the encoding of segment names, the FIF specification requires
all segment names to be encoded using UTF8. If stream name is
unspecified, implementations should open the stream named ``default''.

\item {\em Attributes} are a list of key/value pairs stored at each
stream's ``properties'' segment (e.g. ``stream/properties''). The
``properties'' file is a text file which stores attributes one on each
line. Attribute lines consist of the key, immediately followed by
``='' for text values or ``:'' for binary values. This is immediately
followed by the encoded value. Values containing text MUST be encoded
using UTF8, while values containing binary data MAY be encoded using
Base64. If keys are repeated, their relative order MUST be preserved
by implementations, but different keys may be presented in any order.

Attributes MUST be specified at the top level of each volume
(i.e. must have a segment named ``properties''). The volume attributes
are used to specify the volume UUID.

%about the stream. A properties file also exists at the top
%level of the ZIP hierarchy to store global information such as the
%volumes UUID, the FIF version and other volumes which make up the 

\item {\em A FIF file} is a collection of volumes with the same
UUID. The UUID is generated according to RFC4122 for each new FIF
file. As new volumes are created for the same file, the UUID is copied
to all related volumes. When a FIF file is opened, all its volumes are
loaded and merged in such a way that all the segments from all the
volumes are visible as if they were all found in the same volume.

\end{itemize}

\label{target_reference}
{\em A target reference} is a way of referencing objects. This is used
in a number of places which will be highlighted below. Using
references it is possible for the FIF file to refer to objects
embedded within itself, or within other FIF files. Its is also
possible to refer to external flat files. A number of usage scenarios
are described in Section \ref{usage_scenarios}. The reference is
specified with the following conventions:

\begin{itemize}
\item A reference starting with {\em file://} refers to an external
file. The external file reference must be sanitised (to remove
.. directory traversal) and rooted at the current directory. A
filename of ``.'' refers to the current FIF volume.

\item A reference starting with {\em http://} refers to a HTTP
object which will be fetched. Support for this is optional.

\item A reference in the format {\em fif://UUID/stream/segment} refers
to an external FIF file set (identified by its UUID). If the segment
is missing (i.e. the reference ends with a ``/''), the reference is
for the entire stream. We do not specify a way of actually resolving
the UUID into a physical locations. This can achieved by
implementations using many methods, such as Active Directory, LDAP,
DNS, flat files or SQL databases.

\item A references ending with a ``/'' signify a reference to a
stream in the current FIF file. The stream will be opened in its
entirety. If the reference does not end with a ``/'', the reference is
for a single segment.
\end{itemize}

\subsection{FIF Volumes and segment merging}
There are a number of aspects in the Zip file format specifications
which we do not utilize. For example, the Zip64 specification allows
for a multitude of encryption and hashing algorithms. Some of these
features however, seem to be patent encumbered. Since the FIF
specification aims to separate high level information such as hashes,
cryptography and signatures from the low bit level representation, we
implement those features at a higher level.

In many forensic applications, individual segments within the volume
need to be updated \cite{AFF}. These updates can cause the volume to
become fragmented as holes appear within the middle of the volume, and
updated segments are added at the end.

When we wish to add a new segment to an existing volume, the new
segment header SHOULD overwrite the volume central directory, and the
central directory should be rewritten including the new entry
immediately after the last file in the archive. If it is not possible
to overwrite the file, the new segment can be written at the end,
followed by an updated copy of the central directory (in that case the
old central directory remains in the file). This is illustrated in
Figure \ref{zip_structure}. Implementations may choose to delay
writing the central directory until the file is closed.

A segment within the archive is considered to be updated when a new
segment is added to the archive with the same name and a later
timestamp. Implementations MUST satisfy read requests for duplicate
segment names with those segments with the later timestamp, or if the
two timestamps are the same, the segment which appears at a later
offset in the volume. This effectively allows for a segment to be
updated without leading to internal volume fragmentation.

The fact that the older version of all updated segments remains intact
within each volume can be used for auditing, or to allow a rollback to
previous versions of the segment. The {\em frepack} tool is provided
to repack, split and manage FIF volumes by creating new volumes and
redistributing segments among them.

Note that we do not rely on Zip64's built-in support for splitting
archives at all (although implementations should be able to read such
files). Each volume is a complete and stand alone ZIP file. It is the
FIF implementation which considers the segments contained within it to
belong to a larger collection. The reason behind this decision is that
often it is needed to add new volumes to an existing set without
modifying the existing set at all.

Consider the typical usage scenario depicted in Figure \ref{usage}, of
a FIF file which contains a disk image. This volume is distributed to
two independent analysts, which wish to add new streams to the FIF
file (for example the result of their analysis). In this case they can
each create a new volume which extends to original volume and save
their analysis on this new volume. Now they only need to share this
new volume with other analysts who also have a copy of the old volume
to interchange their findings. 

\begin{figure}[tb]
  \begin{center}
  \mbox{\epsfxsize=0.6\columnwidth \epsffile{usage1.eps}}

  \caption{A typical usage scenario. Both Alice and Bob receive a FIF
  volume but work independently. Rather than modifying the volume,
  they each create another volume and save their results to the new
  volume. They can now exchange the smaller new volumes and
  effectively merge their results into the same FIF set.}

  \label{usage}
  \end{center}
\end{figure}

This is made possible because each volume is independent of one
another, and can be loosely collated into a bigger FIF file
set.

\subsection{FIF Streams}
The above section explained how FIF file sets can be split into
volumes, each containing segments. When the entire FIF file set is
loaded, segments may be fetched from any volume. The present section
describes how these individual segments are used to form {\em stream
abstractions}.

A stream is a high level abstraction of a single source of data. For
example, a stream may contain a disk image or a network
capture. Although we do not specify the exact API, implementations
MUST make a stream opened for reading have at a minimum a read, seek
and tell methods. Seeking MUST support the whence argument as
described in the standard C implementation (i.e. allow seeking to the
end of the stream).

Streams opened for writing MAY limit support for seeking, as efficient
seeking in compressed streams may not be possible. Applications should
avoid needing to seek in output streams, and try to structure writes
serially. It is usually possible to reorder a sequence of non
overlapping random writes into an Image stream and a Map Stream (These
are discussed in Sections \ref{image_stream} and
\ref{map_stream}). Implementations are free to hide the inability to
seek in writing streams by automatically implementing such a scheme,
but this is not mandated by the specification.

All streams within the FIF file MUST have a properties segment. The
properties segment describes the stream attributes as specified
previously. Streams must have the {\em type} attribute which allows
implementations to determine how they should be processed. 

\section{Standard FIF segments}
The FIF specification defines a number of basic types, but extensions
are encouraged. Future versions of the specification might standardize
further types. Implementations MUST implement the basic types.

\subsection{The Image Stream}
\label{image_stream}
The {\em Image} stream ({\em type=image}) contains a single read only
forensic data source. For example, this Stream might contains a hard
disk image, a memory image or a network capture (in PCAP format). The
Image stream provides random read access into the stream (i.e. allows
for randomly seeking the stream to any point). The {\em size}
attribute MUST be specified to determine how large the stream is.

The image itself is stored in chunks within the FIF file. Chunks are
segments named as an 8 digit, zero padded decimal integer
representation of their chunk id (e.g. ``default/00000032''). Image
streams must specify the {\em chunk\_size} attribute, as the number of
image bytes each chunk contains. Chunks may be compressed at the
underlying Zip container level, using any of the compression
algorithms specified by the zip specifications.

Chunks can optionally be individually hashed, allowing for detection
of modifications. The attribute {\em hash\_type} specifies the type of
hash used (implementations SHOULD support md5,sha1 and sha256, but can
define others). The hashes are stored in any number of segments within
the stream, of arbitrary name. The hash segment names is provided by
using the {\em hash} stream attribute.

Each hash segment MUST be a list of a chunk id encoded in 32 bit
little endian integer format followed by the hash (the length of which
depends on the hash itself). This approach is illustrated in Figure
\ref{hash_index}. 

Hash segments can contain any number of chunk hashes in them. It is
recommended that a hash segment be created when a volume is closed to
cover all the chunks within that volume. This allows for hashes to be
verified even if some volumes are missing. It is permitted for a hash
segment to update a hash of a chunk previously set by an earlier hash
segment - this may be required when a chunk is updated. The hash
segment can then be signed to assure the integrity of the updated
segment.

\begin{figure}[tb]
  \begin{center}
  \mbox{\epsfxsize=0.6\columnwidth \epsffile{hash.eps}}

  \caption{The structure of a hashing segment. The attributes {\em
  hash} and {\em hash\_type} declare the hash segment. The segment
  contains a list of integer encoded chunk id followed by an unencoded
  hash for each chunk.}

  \label{hash_index}
  \end{center}
\end{figure}

This design differs from AFF, which creates a separate segment for
each hash. The Zip headers are more verbose than the AFF segment
headers, and typically FIF chunks are much smaller (default 32kb, vs
16Mb for AFF). Therefore, creating a new segment for each hash value
results in more overheads in the FIF format. By packing the hashes
into a few segments it is possible to reduce this overhead to a
minimum.

Hashes are calculated in an identical way to that defined by AFF,
thats is the full name of the segment (including stream component) is
followed by a single NULL byte, followed by the (uncompressed) content
of the chunk. The inclusion of the segment name ensure that even
identical chunks in content will have a different hash.

\subsection{The Map Stream}
\label{map_stream}
Linear transformations of data are commonplace in forensic
analysis. For example, a file is often simply a collection of bytes
drawn from an image. A TCP/IP stream is simply a collection of
payloads from selected network packets. Sometimes the same data may be
viewed in a number of ways - for example a Virtual Address Space is a
mapping of the Physical Address Space through a page table
transformation. It is, therefore, beneficial to define a way in which
the underlying storage system can apply transformations to existing
data to produce transformed data.

For example, Zero Storage Carving \cite{Meijer2006}, is a way of
specifying carved files in terms of a sequence of blocks taken from
the image. \cite{Cohen2007} extended this concept to an arbitrary
mapping function. This is the approach chosen in this specification
due to its flexibility. 

The Map stream defines a mapping function, as a piecewise continuous
linear transform of one or more {\em target} streams to produce a new
{\em stream}. Target streams are specified by using ``target''
attribute, which may be used many times to provide a list of targets.

The mapping function file consists of a series of lines, each
containing three 64 bit integers separated by comma, and encoded using
decimal notation. The integers represent stream offset, target offset
and target number. Target numbers are an index to the list of targets
given in the attribute section (list index starts at zero for the
first entry).

Denoting the stream offset by $x$, and the target offset by $y$, the
map specifies a set of points $(X_i,Y_i,T_i)$. Read requests for a
byte at a mapped stream offset $x$ can then be satisfied by reading a
byte from target $T_i$ at offset $y$ given by:
\begin{eqnarray}
y = (x - X_i) + Y_i & &
\forall x \in \left [X_i, X_i+1 \right )
\end{eqnarray}

For example, consider the following map:
\begin{verbatim*}
0,0,0
4096,10000,0
8192,5000,0
\end{verbatim*}

To read this stream we satisfy read requests of offsets between 0 and
4095 in the stream from offset 0 in target 0. Requests for bytes
between 4096 and 8191 are fetched from target 0 at offset
10000. Finally bytes after 8192 (until the specified size of the
stream) are fetched from offset 5000 in target 0.

In order to efficiently express periodic maps such as those found in
RAID arrays, the Map stream may be provided with two optional
parameters a {\em target\_period} ($T_p$), and {\em stream\_period}
($S_p$). If specified, the above relation becomes:
\begin{eqnarray*}
p &:=& floor\left (\frac{x}{S_p} \right) \\
x' &:=& mod(x ,S_p)  \\   \label{eq:no1}
y &:=& (x'-X_i) + Y_i + p \times T_p
\end{eqnarray*}

Where $mod$ is the modulus function, while $floor$ signifies integer
division. For example consider the following, which corresponds to a 3
disk RAID-5 array:
\begin{verbatim*}
stream_period=393216
target_period=196608

0,0,1
65536,0,0
131072,65536,2
196608,65536,1
262144,131072,0
327680,131072,2
\end{verbatim*}

\subsection{The Overlay stream}
The Overlay stream is a variant of the {\em Image} stream in that it
allows for images to be stored in (possibly compressed) chunks. The
main utility of the Overlay stream is in providing transparent access
to other forensic formats, such as EWF or AFF. These formats also use
chunk based compression to provide the ability to randomly seek while
reading. To access these file formats we only need to have an index of
each chunk offset, and then directly use the overlayed files. The {\em
ewf2fif} tool provides such an overlay feature for EWF volumes by
employing libewf to scan the internal data structures.

Therefore, the {\em chunk\_size} attribute must be specified. In
addition the {\em compression\_type} attribute MAY be specified. The
attribute should contain an integer corresponding to a suitable Zip
compression scheme (e.g. DEFLATE). If not specified it is assumed
that no compression is used.

The ``target'' stream attribute may be specified multiple times and
refer to external files (See section \ref{target_reference}). There
can be a number of overlay segments named ``stream name/overlay.00''
which are all merged to a single overlay. If more than one overlay is
present, the attribute {\em overlays} MUST be specify how many.

The overlay segment contains a series of lines with comma delimited,
decimal encoded, 64 bit integers representing chunk number, target
offset, target length and target number. Target number is an index
into the targets defined in the attributes (count starts with zero).
Chunks are then fetched from the specified target and decompressed if
necessary.

It is possible to refer to the current file by providing a target of
``file://.''. This can be useful for modifying an existing EWF file to
be a FIF file. Since Zip files are normally read from the end of the
file, but EWF and AFF are both read from the front of the file it may
be possible to append a FIF file to the end of an EWF file without
interfering with the overlayed file. In this case the converted file
can still be used as an EWF file without change, but it can also be
used as a FIF file.

In image streams some chunks may compress very well. In that case, the
overheads introduced by the Zip File Header for each chunk in the
Image stream may become unacceptably high. In that case its possible
to use an {\em Overlay stream} to coalesce chunks into larger
segments. This approach is illustrated in Figure \ref{overlay}.

\begin{figure}[tb]
  \begin{center}
  \mbox{\epsfxsize=0.6\columnwidth \epsffile{overlay.eps}}
  \caption{The use of an Overlay Stream to overlay an image with
coalesced chunks.}
  \label{overlay}
  \end{center}
\end{figure}

In the above figure a segment is written to the FIF volume which
contains a number of chunks back to back. An overlay stream then uses
direct references to each compressed chunk within the coalesced
segment. The target is then specified as the segment name. Although
this technique is valid, it is generally discouraged since it breaks
the appealing simplicity of the standard Image Stream.  It is no
longer possible to simply unzip all the chunks and concatenate them
together to recover the original image.


\subsection{The Private stream}
Often forensic software needs to store internal state, such as the
current state of the GUI, or internal data structures which may be
required for caching. Usually, software create additional cache files
to maintain this information. It is advantageous to be able to store
these in the evidence file itself. The evidence file can then be
re-opened by the software at a later stage and private data can be
retrieved and used directly. Such private application data can be
stored in a Private stream. There is no specification of what can be
stored in the private stream, and applications with private streams
should be able to store arbitrary segments in any format at all.

It is recommended that applications name their private segment
sufficiently accurately so as not to be confused with other
applications, or different versions of the same application
(e.g. ``pyflag/0.87/cache/'').

\subsection{Encrypted Streams}
Encryption is an important property in an evidence file format
\cite{AFF}. In particular with the FIF format, multiple streams may be
present in the file set, and often different access levels are
desired. For example, for evidence set containing both network
captures and disk images it may be desirable to limit access to
streams based on legal authorizations.

Although the Zip64 standard specifies encryption, it is not suitable
for our purposes since it encrypts each segment separately, and does
not specify a sufficiently flexible scheme (e.g. support for PKI, PGP
keys). Segment based encryption may lead to information leakage when
segments are compressed, as the uncompressed size of the segment may
be deduced.

The Encrypted Stream ({\em type=encrypted}) SHOULD be implemented by
FIF implementations, but may be omitted with an obvious loss of
functionality (Encryption may be prohibited or restricted in some
jurisdictions).

The Encrypted Stream is similar to the Image Stream above in that data
is written out in chunks (although its probably not effective to
compress these chunks at all). Each chunk is to be encrypted upon
writing and transparently decrypted using a scheme declared in the
{\em scheme} attribute. 

The Encrypted Stream may contain any data at all. It is useful
however, to store an actual FIF volume within the Encrypted
stream. This provides block level encryption for the contained FIF
volume. It is recommended that Encrypted Streams containing a FIF
volume set an attribute ({\em content-type=application/x-fif-volume})
to allow implementations to automatically recognize volumes. This
approach is illustrated in Figure \ref{crypted_fif}.

\begin{figure}[tb]
  \begin{center}
  \mbox{\epsfxsize=0.8\columnwidth \epsffile{crypted.eps}}
  \caption{Embedding an encrypted FIF volume within an Encrypted Stream.}
  \label{crypted_fif}
  \end{center}
\end{figure}

The result is that a number of FIF volume are used as {\em Container
Volumes} to provide storage for Encrypted Streams. The main {\em
Embedded Volume}, which actually contains data is stored within the
Encrypted Stream, effectively distributed throughout the container
volumes. Note that the Container Volume may contain several Encrypted
Streams and therefore contain multiple Encrypted FIF
Volumes. Container Volumes may contain non encrypted streams as well,
and may implement different encryption schemes and keys for each
Encrypted scheme. This effectively allows arbitrary access policies to
be implemented as only volumes which can be accessed can be merged.

Implementations should create embedded FIF volumes as extensions to
the container volumes (i.e. with the same UUID). Thus when embedded
volumes are opened, their streams become automatically viewable as
part of the evidence set.

\subsection{Encryption Schemes}
We specify a number of encryption schemes, but extra schemes may be
defined by the implementation.

\subsubsection{Null Encryption}
This scheme ({\em scheme=null}) specifies no encryption at all. This
may be useful for testing an implementation, but obviously provides
no real security.

\subsubsection{AES-SHA-PSK}
This scheme ({\em scheme=aes-sha-psk}) uses AES for block level
encryption, with the following SHA based ESSIV scheme, and Pre-Shared
Key (passphrase).

When creating a new volume, a master key is generated using the first
128 bits of a SHA1 hash of the Pre-Shared-Key appended to a 64 bit
random salt:
\begin{eqnarray}
Key_{Master} = \left | SHA1(salt + PSK) \right | _{128}
\end{eqnarray}

For each chunk, the chunk IV is obtained by taking the first 128 bits
of the SHA1 hash of the chunk id encoded as a 32 bit little endian
integer, followed by the master key:
\begin{eqnarray}
IV = \left | SHA1(chunk\_id + Key_{Master}) \right | _{128}
\end{eqnarray}

The block is then encrypted or decrypted using AES with this IV.

Implementations MUST specify the salt as a stream attribute named {\em
salt} in base 64 encoding. Implementations are free to specify any API
for passing the Pre-Shared Key, for example the PSK can be specified
in a configuration file, typed in at the terminal, passed in using
process environment variables, or encoded within the FIF filename
itself.

\subsection{Optional features}
Implementations may implement the following features to simplify the
interfaces.

\subsubsection{Automated volume loading}
FIF volumes are effectively independent, as each volume does not need
to know anything about other volumes. This makes it necessary to
specify in advance all volumes for the implementation to merge them
all. In particular it may be necessary to specify encrypted volumes
(which may not be read if the user has no authorization for the
Encrypted Stream).

As an optional enhancement FIF specifies a volume attribute named {\em
volume} (i.e. an attribute present in the top level ``properties''
segment). This is a target reference (see section
\ref{target_reference}) for other volumes. 
Implementations should attempt to open external references (e.g. using
the {\em file://} convention) before internal references. As new
volumes are merged their volume attributes must be scanned for
additional references. Each volume must list all other known volumes
as volume attributes.

In this way, encrypted volumes, and external volumes can be located
and found automatically.


\section{Implementation Recommendations}
Since the individual chunks are simply files in a Zip archive, any zip
library can be utilized for reading these chunks. However, this may
not be efficient since simple Zip implementations might rescan the
Central Directory for each segment request. Since in practice there
can be a large number of chunks in each volume, it is recommended that
implementations build an index of offsets and length of each chunk
into the file. This kind of index is very similar to the strategy
other file formats use \cite{EWF}. The index may then be saved to the
file by use of a Private stream.

Zip64 specifies duplicate data in the Central Directory entry for each
segment and its File Header (such as filename, size, CRC etc). Many
implementations only populate this information in one of these
places. In the interest of robustness, it is recommended that FIF
implementations populate both places at the slight expense of higher
overheads, because this can be used to recover and correct damaged
files. If the central directory is lost, it is possible to scan
through the zip file and repair the central directory from the File
headers.

The underlying Zip implementation should support multiple writers
simultaneously by interleaving their writes to the file. For example,
for two streams being written concurrently, the new segments can be
added to the same archive in any order. In addition, the volume may be
closed and a new volume opened without writers being aware of
this. Since all segments from all volumes are merged, streams can be
split arbitrarily across volumes in any way. It is recommended that
stream properties be written to each volume to ensure at least some of
the stream can be used even if some volumes are lost.

\section{Usage Scenarios}
In this section we describe how a FIF file format may be used in
various situations. Many of those can be solved using other forensic
file formats, but often in a more awkward way.

\subsubsection{Rapidly converting a set of DD images}
Many hardware devices are available to acquire hard disks in the
fields. These often produce a set of uncompressed images split at a
certain size. If the images are split at exactly the same size its
possible to create a FIF archive consisting of a single Overlay
Stream, with a chunk\_size set to the size of each of the images. The
images can then be listed in order as external targets (e.g. {\em
target=file://disk1.dd}). This overlay can be created instantly
without needing to re-compress any of the images. In addition, digital
signatures can be generated for the whole stream or for each segment.

\subsubsection{Rapid conversion of EWF file sets}
Much existing evidence has been acquired using the EWF file
format. This format, similarly, consists of a series of chunks which
may be compressed, with interdispersed indexes. A tool such as
``ewf2fif'' is able to utilize the libewf library to create an Overlay
stream of the original image without the need to re-compress it. This
conversion is very quick and the resulting FIF file is very small -
each volume in the EWF file set is referenced through an external
target reference, and the Overlay Stream is built as an index of each
chunk location.

\subsubsection{Acquisition of RAID disks}
Often disks in a system are grouped into RAID devices, commonly RAID-5
or RAID-0. Previously, if disks were acquired independently, they
would need to be analysed using a tool which was able to reassemble
RAID devices.

With the FIF format, each of the disks can be acquired as a separate
Image Stream. Finally a tool such as PyFlag may be used to deduce the
RAID map, which can be appended to the FIF file as a Map Stream. This
Map Stream can then be opened by any tool without the tool needing to
have explicit support for RAID reassembling.

\subsubsection{Cryptographic management of evidence}
A FIF archive may hold multiple encrypted volumes, each in its own
Encrypted Stream. Each of those streams is encrypted using a different
master key, and therefore can have different passphrases, and can be
assigned to different users by encrypting the master key with
different X509 certificates. Its is also possible for users to create
non-encrypted volumes within the FIF file.

This can be used to enforce access controls in line with current
legislative requirements. For example, within the same investigation
different material is often obtained under different warrants
(e.g. wiretap authorizations are different from search
warrants). Therefore, different investigators and analysts need
different access to the different streams. However, the analysts may
still store the results of their analysis in an unencrypted form, or
assign others permissions to decrypt their analysis results, without
providing access to the underlying data. 

This can be used in sharing meta data (e.g. Map Streams of files of
interest) between analysts, without needing to provide access to the
underlying data.

\subsubsection{Forensic Application State}
Often forensic applications need to store files other than the
evidence itself - for example, they might need to store internal data,
annotations, keyword hits etc. Currently these applications store the
data in a proprietary external file or database. This makes it
difficult to archive because the evidence itself may become separated
from the case file.

It is advantageous for these applications to store their state within
the evidence file itself using a Private Stream. Then when opening the
evidence file again, the results of their analysis will become
available.

\subsubsection{Merging of evidence set}
In this common usage case, Bob, goes on site to image one hard disk,
while Alice independently images a second hard disk. After returning
to the office they both realise their images belong to the same
set. They merge their images, by updating the UUIDs on one of the
volume set to now belong to the other volume set - the merge is almost
instantaneous as they only need to write an extra ``properties'' file
on the merged volumes.


\bibliography{IEEEabrv,paper}
\end{document}
